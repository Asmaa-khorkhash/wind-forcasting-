{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport tensorflow as tf","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-11-15T22:41:08.870476Z","iopub.execute_input":"2022-11-15T22:41:08.870841Z","iopub.status.idle":"2022-11-15T22:41:12.884746Z","shell.execute_reply.started":"2022-11-15T22:41:08.870811Z","shell.execute_reply":"2022-11-15T22:41:12.883761Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/wind-power-forecasting/Turbine_Data.csv')","metadata":{"execution":{"iopub.status.busy":"2022-11-15T22:41:12.887007Z","iopub.execute_input":"2022-11-15T22:41:12.888006Z","iopub.status.idle":"2022-11-15T22:41:13.576232Z","shell.execute_reply.started":"2022-11-15T22:41:12.887966Z","shell.execute_reply":"2022-11-15T22:41:13.575225Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"df.drop(columns = ['WTG','ControlBoxTemperature','Unnamed: 0'], inplace = True) #We drop WTG because every value was the same","metadata":{"execution":{"iopub.status.busy":"2022-11-15T22:41:13.577481Z","iopub.execute_input":"2022-11-15T22:41:13.577860Z","iopub.status.idle":"2022-11-15T22:41:13.597854Z","shell.execute_reply.started":"2022-11-15T22:41:13.577815Z","shell.execute_reply":"2022-11-15T22:41:13.596773Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"columns = ['AmbientTemperatue' ,\n           'BearingShaftTemperature',\n           'Blade1PitchAngle', \n           'Blade2PitchAngle' ,\n           'Blade3PitchAngle',\n           'GearboxBearingTemperature',\n           'GearboxOilTemperature',\n           'GeneratorRPM','GeneratorWinding1Temperature','GeneratorWinding2Temperature',\n           'HubTemperature',\n           'MainBoxTemperature',\n           'NacellePosition',\n           'ReactivePower',\n           'RotorRPM',\n           'TurbineStatus', \n           'WindDirection',\n           'WindSpeed']\nfor n in columns:\n    df[n].fillna(df[n].median(),inplace = True)\nfor d in df:\n    df.dropna(axis=0,how = 'any',inplace = True)","metadata":{"execution":{"iopub.status.busy":"2022-11-15T22:41:13.600851Z","iopub.execute_input":"2022-11-15T22:41:13.601472Z","iopub.status.idle":"2022-11-15T22:41:13.834011Z","shell.execute_reply.started":"2022-11-15T22:41:13.601437Z","shell.execute_reply":"2022-11-15T22:41:13.832985Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2022-11-15T22:41:13.835275Z","iopub.execute_input":"2022-11-15T22:41:13.835641Z","iopub.status.idle":"2022-11-15T22:41:13.846557Z","shell.execute_reply.started":"2022-11-15T22:41:13.835607Z","shell.execute_reply":"2022-11-15T22:41:13.845376Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"(94750, 19)"},"metadata":{}}]},{"cell_type":"code","source":"target=['ActivePower']\nX = df[columns]\nY= df[target]","metadata":{"execution":{"iopub.status.busy":"2022-11-15T22:41:13.848345Z","iopub.execute_input":"2022-11-15T22:41:13.849033Z","iopub.status.idle":"2022-11-15T22:41:13.858943Z","shell.execute_reply.started":"2022-11-15T22:41:13.848819Z","shell.execute_reply":"2022-11-15T22:41:13.858009Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2022-11-15T22:41:13.861430Z","iopub.execute_input":"2022-11-15T22:41:13.862252Z","iopub.status.idle":"2022-11-15T22:41:13.892073Z","shell.execute_reply.started":"2022-11-15T22:41:13.862215Z","shell.execute_reply":"2022-11-15T22:41:13.891017Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"        ActivePower  AmbientTemperatue  BearingShaftTemperature  \\\n144       -5.357727          23.148729                42.910877   \n145       -5.822360          23.039754                42.910877   \n146       -5.279409          22.948703                42.910877   \n147       -4.648054          22.966851                42.910877   \n148       -4.684632          22.936520                42.910877   \n...             ...                ...                      ...   \n118219    70.044465          27.523741                45.711129   \n118220    40.833474          27.602882                45.598573   \n118221    20.777790          27.560925                45.462045   \n118222    62.091039          27.810472                45.343827   \n118223    68.664425          27.915828                45.231610   \n\n        Blade1PitchAngle  Blade2PitchAngle  Blade3PitchAngle  \\\n144             0.394399          0.888977          0.888977   \n145             0.394399          0.888977          0.888977   \n146             0.394399          0.888977          0.888977   \n147             0.394399          0.888977          0.888977   \n148             0.394399          0.888977          0.888977   \n...                  ...               ...               ...   \n118219          1.515669          1.950088          1.950088   \n118220          1.702809          2.136732          2.136732   \n118221          1.706214          2.139664          2.139664   \n118222          1.575352          2.009781          2.009781   \n118223          1.499323          1.933124          1.933124   \n\n        GearboxBearingTemperature  GearboxOilTemperature  GeneratorRPM  \\\n144                     64.834662              57.196089   1124.860720   \n145                     64.834662              57.196089   1124.860720   \n146                     64.834662              57.196089   1124.860720   \n147                     64.834662              57.196089   1124.860720   \n148                     64.834662              57.196089   1124.860720   \n...                           ...                    ...           ...   \n118219                  59.821165              55.193793   1029.870744   \n118220                  59.142038              54.798545   1030.160478   \n118221                  58.439439              54.380456   1030.137822   \n118222                  58.205413              54.079014   1030.178178   \n118223                  58.581716              54.080505   1029.834789   \n\n        GeneratorWinding1Temperature  GeneratorWinding2Temperature  \\\n144                        65.788800                     65.004946   \n145                        65.788800                     65.004946   \n146                        65.788800                     65.004946   \n147                        65.788800                     65.004946   \n148                        65.788800                     65.004946   \n...                              ...                           ...   \n118219                     59.060367                     58.148777   \n118220                     58.452003                     57.550367   \n118221                     58.034071                     57.099335   \n118222                     57.795387                     56.847239   \n118223                     57.694813                     56.741040   \n\n        HubTemperature  MainBoxTemperature  NacellePosition  ReactivePower  \\\n144          37.003815           39.491310         8.000000      -9.960830   \n145          37.003815           39.491310       300.428571      -9.628441   \n146          37.003815           39.491310       340.000000      -9.491235   \n147          37.003815           39.491310       345.000000      -9.856136   \n148          37.003815           39.491310       345.000000      -9.745593   \n...                ...                 ...              ...            ...   \n118219       39.008931           36.476562       178.000000      13.775785   \n118220       39.006759           36.328125       178.000000       8.088928   \n118221       39.003815           36.131944       178.000000       4.355978   \n118222       39.003815           36.007805       190.000000      12.018077   \n118223       39.003815           35.914062       203.000000      14.439669   \n\n         RotorRPM  TurbineStatus  WindDirection  WindSpeed  \n144     10.098702            2.0       8.000000   2.279088  \n145     10.098702            2.0     300.428571   2.339343  \n146     10.098702            2.0     340.000000   2.455610  \n147     10.098702            2.0     345.000000   2.026754  \n148     10.098702            2.0     345.000000   1.831420  \n...           ...            ...            ...        ...  \n118219   9.234004            2.0     178.000000   3.533445  \n118220   9.229370            2.0     178.000000   3.261231  \n118221   9.236802            2.0     178.000000   3.331839  \n118222   9.237374            2.0     190.000000   3.284468  \n118223   9.235532            2.0     203.000000   3.475205  \n\n[94750 rows x 19 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ActivePower</th>\n      <th>AmbientTemperatue</th>\n      <th>BearingShaftTemperature</th>\n      <th>Blade1PitchAngle</th>\n      <th>Blade2PitchAngle</th>\n      <th>Blade3PitchAngle</th>\n      <th>GearboxBearingTemperature</th>\n      <th>GearboxOilTemperature</th>\n      <th>GeneratorRPM</th>\n      <th>GeneratorWinding1Temperature</th>\n      <th>GeneratorWinding2Temperature</th>\n      <th>HubTemperature</th>\n      <th>MainBoxTemperature</th>\n      <th>NacellePosition</th>\n      <th>ReactivePower</th>\n      <th>RotorRPM</th>\n      <th>TurbineStatus</th>\n      <th>WindDirection</th>\n      <th>WindSpeed</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>144</th>\n      <td>-5.357727</td>\n      <td>23.148729</td>\n      <td>42.910877</td>\n      <td>0.394399</td>\n      <td>0.888977</td>\n      <td>0.888977</td>\n      <td>64.834662</td>\n      <td>57.196089</td>\n      <td>1124.860720</td>\n      <td>65.788800</td>\n      <td>65.004946</td>\n      <td>37.003815</td>\n      <td>39.491310</td>\n      <td>8.000000</td>\n      <td>-9.960830</td>\n      <td>10.098702</td>\n      <td>2.0</td>\n      <td>8.000000</td>\n      <td>2.279088</td>\n    </tr>\n    <tr>\n      <th>145</th>\n      <td>-5.822360</td>\n      <td>23.039754</td>\n      <td>42.910877</td>\n      <td>0.394399</td>\n      <td>0.888977</td>\n      <td>0.888977</td>\n      <td>64.834662</td>\n      <td>57.196089</td>\n      <td>1124.860720</td>\n      <td>65.788800</td>\n      <td>65.004946</td>\n      <td>37.003815</td>\n      <td>39.491310</td>\n      <td>300.428571</td>\n      <td>-9.628441</td>\n      <td>10.098702</td>\n      <td>2.0</td>\n      <td>300.428571</td>\n      <td>2.339343</td>\n    </tr>\n    <tr>\n      <th>146</th>\n      <td>-5.279409</td>\n      <td>22.948703</td>\n      <td>42.910877</td>\n      <td>0.394399</td>\n      <td>0.888977</td>\n      <td>0.888977</td>\n      <td>64.834662</td>\n      <td>57.196089</td>\n      <td>1124.860720</td>\n      <td>65.788800</td>\n      <td>65.004946</td>\n      <td>37.003815</td>\n      <td>39.491310</td>\n      <td>340.000000</td>\n      <td>-9.491235</td>\n      <td>10.098702</td>\n      <td>2.0</td>\n      <td>340.000000</td>\n      <td>2.455610</td>\n    </tr>\n    <tr>\n      <th>147</th>\n      <td>-4.648054</td>\n      <td>22.966851</td>\n      <td>42.910877</td>\n      <td>0.394399</td>\n      <td>0.888977</td>\n      <td>0.888977</td>\n      <td>64.834662</td>\n      <td>57.196089</td>\n      <td>1124.860720</td>\n      <td>65.788800</td>\n      <td>65.004946</td>\n      <td>37.003815</td>\n      <td>39.491310</td>\n      <td>345.000000</td>\n      <td>-9.856136</td>\n      <td>10.098702</td>\n      <td>2.0</td>\n      <td>345.000000</td>\n      <td>2.026754</td>\n    </tr>\n    <tr>\n      <th>148</th>\n      <td>-4.684632</td>\n      <td>22.936520</td>\n      <td>42.910877</td>\n      <td>0.394399</td>\n      <td>0.888977</td>\n      <td>0.888977</td>\n      <td>64.834662</td>\n      <td>57.196089</td>\n      <td>1124.860720</td>\n      <td>65.788800</td>\n      <td>65.004946</td>\n      <td>37.003815</td>\n      <td>39.491310</td>\n      <td>345.000000</td>\n      <td>-9.745593</td>\n      <td>10.098702</td>\n      <td>2.0</td>\n      <td>345.000000</td>\n      <td>1.831420</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>118219</th>\n      <td>70.044465</td>\n      <td>27.523741</td>\n      <td>45.711129</td>\n      <td>1.515669</td>\n      <td>1.950088</td>\n      <td>1.950088</td>\n      <td>59.821165</td>\n      <td>55.193793</td>\n      <td>1029.870744</td>\n      <td>59.060367</td>\n      <td>58.148777</td>\n      <td>39.008931</td>\n      <td>36.476562</td>\n      <td>178.000000</td>\n      <td>13.775785</td>\n      <td>9.234004</td>\n      <td>2.0</td>\n      <td>178.000000</td>\n      <td>3.533445</td>\n    </tr>\n    <tr>\n      <th>118220</th>\n      <td>40.833474</td>\n      <td>27.602882</td>\n      <td>45.598573</td>\n      <td>1.702809</td>\n      <td>2.136732</td>\n      <td>2.136732</td>\n      <td>59.142038</td>\n      <td>54.798545</td>\n      <td>1030.160478</td>\n      <td>58.452003</td>\n      <td>57.550367</td>\n      <td>39.006759</td>\n      <td>36.328125</td>\n      <td>178.000000</td>\n      <td>8.088928</td>\n      <td>9.229370</td>\n      <td>2.0</td>\n      <td>178.000000</td>\n      <td>3.261231</td>\n    </tr>\n    <tr>\n      <th>118221</th>\n      <td>20.777790</td>\n      <td>27.560925</td>\n      <td>45.462045</td>\n      <td>1.706214</td>\n      <td>2.139664</td>\n      <td>2.139664</td>\n      <td>58.439439</td>\n      <td>54.380456</td>\n      <td>1030.137822</td>\n      <td>58.034071</td>\n      <td>57.099335</td>\n      <td>39.003815</td>\n      <td>36.131944</td>\n      <td>178.000000</td>\n      <td>4.355978</td>\n      <td>9.236802</td>\n      <td>2.0</td>\n      <td>178.000000</td>\n      <td>3.331839</td>\n    </tr>\n    <tr>\n      <th>118222</th>\n      <td>62.091039</td>\n      <td>27.810472</td>\n      <td>45.343827</td>\n      <td>1.575352</td>\n      <td>2.009781</td>\n      <td>2.009781</td>\n      <td>58.205413</td>\n      <td>54.079014</td>\n      <td>1030.178178</td>\n      <td>57.795387</td>\n      <td>56.847239</td>\n      <td>39.003815</td>\n      <td>36.007805</td>\n      <td>190.000000</td>\n      <td>12.018077</td>\n      <td>9.237374</td>\n      <td>2.0</td>\n      <td>190.000000</td>\n      <td>3.284468</td>\n    </tr>\n    <tr>\n      <th>118223</th>\n      <td>68.664425</td>\n      <td>27.915828</td>\n      <td>45.231610</td>\n      <td>1.499323</td>\n      <td>1.933124</td>\n      <td>1.933124</td>\n      <td>58.581716</td>\n      <td>54.080505</td>\n      <td>1029.834789</td>\n      <td>57.694813</td>\n      <td>56.741040</td>\n      <td>39.003815</td>\n      <td>35.914062</td>\n      <td>203.000000</td>\n      <td>14.439669</td>\n      <td>9.235532</td>\n      <td>2.0</td>\n      <td>203.000000</td>\n      <td>3.475205</td>\n    </tr>\n  </tbody>\n</table>\n<p>94750 rows × 19 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(X,Y,test_size=0.3, random_state=1)","metadata":{"execution":{"iopub.status.busy":"2022-11-15T22:41:13.893769Z","iopub.execute_input":"2022-11-15T22:41:13.894116Z","iopub.status.idle":"2022-11-15T22:41:14.184547Z","shell.execute_reply.started":"2022-11-15T22:41:13.894082Z","shell.execute_reply":"2022-11-15T22:41:14.183571Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\ndef scale_data(train, test):\n    scaler = MinMaxScaler().fit(train)\n    return scaler.transform(train), scaler.transform(test), scaler","metadata":{"execution":{"iopub.status.busy":"2022-11-15T22:41:14.186963Z","iopub.execute_input":"2022-11-15T22:41:14.187637Z","iopub.status.idle":"2022-11-15T22:41:14.193144Z","shell.execute_reply.started":"2022-11-15T22:41:14.187597Z","shell.execute_reply":"2022-11-15T22:41:14.192194Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, scaler = scale_data(x_train, x_test)\nY_train, Y_test, scaler = scale_data(y_train, y_test)","metadata":{"execution":{"iopub.status.busy":"2022-11-15T22:41:14.197451Z","iopub.execute_input":"2022-11-15T22:41:14.197906Z","iopub.status.idle":"2022-11-15T22:41:14.224134Z","shell.execute_reply.started":"2022-11-15T22:41:14.197878Z","shell.execute_reply":"2022-11-15T22:41:14.223233Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"X_train = X_train.reshape(X_train.shape[0],1,X_train.shape[1])\nX_test = X_test.reshape(X_test.shape[0],1,X_test.shape[1])","metadata":{"execution":{"iopub.status.busy":"2022-11-15T22:41:14.225687Z","iopub.execute_input":"2022-11-15T22:41:14.226073Z","iopub.status.idle":"2022-11-15T22:41:14.231581Z","shell.execute_reply.started":"2022-11-15T22:41:14.226039Z","shell.execute_reply":"2022-11-15T22:41:14.230474Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"X_val, X_test, y_val, y_test = train_test_split(X_test, Y_test, test_size=0.50, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-11-15T22:41:14.233371Z","iopub.execute_input":"2022-11-15T22:41:14.233835Z","iopub.status.idle":"2022-11-15T22:41:14.247142Z","shell.execute_reply.started":"2022-11-15T22:41:14.233792Z","shell.execute_reply":"2022-11-15T22:41:14.246271Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"X_train.shape , Y_train.shape","metadata":{"execution":{"iopub.status.busy":"2022-11-15T22:41:14.248530Z","iopub.execute_input":"2022-11-15T22:41:14.249399Z","iopub.status.idle":"2022-11-15T22:41:14.256023Z","shell.execute_reply.started":"2022-11-15T22:41:14.249364Z","shell.execute_reply":"2022-11-15T22:41:14.254894Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"((66325, 1, 18), (66325, 1))"},"metadata":{}}]},{"cell_type":"code","source":"def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n    # Normalization and Attention\n    x = layers.LayerNormalization()(inputs)\n    x = layers.MultiHeadAttention(\n        key_dim=head_size, num_heads=num_heads, dropout=dropout\n    )(x, x)\n    x = layers.Dropout(dropout)(x)\n    res = x + inputs\n\n    # Feed Forward Part\n    x = layers.LayerNormalization()(res)\n    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(x)\n    x = layers.Dropout(dropout)(x)\n    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n    return x + res","metadata":{"execution":{"iopub.status.busy":"2022-11-15T22:41:14.257732Z","iopub.execute_input":"2022-11-15T22:41:14.258183Z","iopub.status.idle":"2022-11-15T22:41:14.267202Z","shell.execute_reply.started":"2022-11-15T22:41:14.258148Z","shell.execute_reply":"2022-11-15T22:41:14.265621Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"from tensorflow import keras\nfrom tensorflow.keras import layers","metadata":{"execution":{"iopub.status.busy":"2022-11-15T22:41:14.269956Z","iopub.execute_input":"2022-11-15T22:41:14.270379Z","iopub.status.idle":"2022-11-15T22:41:15.187001Z","shell.execute_reply.started":"2022-11-15T22:41:14.270342Z","shell.execute_reply":"2022-11-15T22:41:15.186038Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def build_model(\n    input_shape,\n    head_size,\n    num_heads,\n    ff_dim,\n    num_transformer_blocks,\n    mlp_units,\n    dropout=0,\n    mlp_dropout=0,\n):\n    inputs = keras.Input(shape=input_shape)\n    x = inputs\n    for _ in range(num_transformer_blocks):\n        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n\n    x = layers.GlobalAveragePooling1D()(x)\n    for dim in mlp_units:\n        x = layers.Dense(dim, activation=\"relu\")(x)\n        x = layers.Dropout(mlp_dropout)(x)\n    outputs = layers.Dense(n_classes, activation=\"linear\")(x)\n    return keras.Model(inputs, outputs)\n","metadata":{"execution":{"iopub.status.busy":"2022-11-15T22:41:15.188522Z","iopub.execute_input":"2022-11-15T22:41:15.188926Z","iopub.status.idle":"2022-11-15T22:41:15.199200Z","shell.execute_reply.started":"2022-11-15T22:41:15.188892Z","shell.execute_reply":"2022-11-15T22:41:15.197543Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"input_shape = X_train.shape[1:]\nn_classes =1\nmodel = build_model(\n    input_shape,\n    head_size=8,\n    num_heads=8,\n    ff_dim=64,\n    num_transformer_blocks=5,\n    mlp_units=[512],\n    mlp_dropout=0.4,\n    dropout=0.1,\n)\n\nmodel.compile(\n    loss=\"mse\",\n    optimizer=keras.optimizers.Adam(),\n)\n\nmodel.summary()\n\ncallbacks = [keras.callbacks.EarlyStopping(patience=10)]","metadata":{"execution":{"iopub.status.busy":"2022-11-15T22:41:15.202678Z","iopub.execute_input":"2022-11-15T22:41:15.203570Z","iopub.status.idle":"2022-11-15T22:41:18.576746Z","shell.execute_reply.started":"2022-11-15T22:41:15.203524Z","shell.execute_reply":"2022-11-15T22:41:18.575778Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"2022-11-15 22:41:15.313052: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-15 22:41:15.433305: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-15 22:41:15.434117: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-15 22:41:15.435375: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2022-11-15 22:41:15.435692: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-15 22:41:15.436432: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-15 22:41:15.437103: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-15 22:41:17.699631: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-15 22:41:17.700501: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-15 22:41:17.701159: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-15 22:41:17.701748: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15401 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"},{"name":"stdout","text":"Model: \"model\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_1 (InputLayer)            [(None, 1, 18)]      0                                            \n__________________________________________________________________________________________________\nlayer_normalization (LayerNorma (None, 1, 18)        36          input_1[0][0]                    \n__________________________________________________________________________________________________\nmulti_head_attention (MultiHead (None, 1, 18)        4818        layer_normalization[0][0]        \n                                                                 layer_normalization[0][0]        \n__________________________________________________________________________________________________\ndropout (Dropout)               (None, 1, 18)        0           multi_head_attention[0][0]       \n__________________________________________________________________________________________________\ntf.__operators__.add (TFOpLambd (None, 1, 18)        0           dropout[0][0]                    \n                                                                 input_1[0][0]                    \n__________________________________________________________________________________________________\nlayer_normalization_1 (LayerNor (None, 1, 18)        36          tf.__operators__.add[0][0]       \n__________________________________________________________________________________________________\nconv1d (Conv1D)                 (None, 1, 64)        1216        layer_normalization_1[0][0]      \n__________________________________________________________________________________________________\ndropout_1 (Dropout)             (None, 1, 64)        0           conv1d[0][0]                     \n__________________________________________________________________________________________________\nconv1d_1 (Conv1D)               (None, 1, 18)        1170        dropout_1[0][0]                  \n__________________________________________________________________________________________________\ntf.__operators__.add_1 (TFOpLam (None, 1, 18)        0           conv1d_1[0][0]                   \n                                                                 tf.__operators__.add[0][0]       \n__________________________________________________________________________________________________\nlayer_normalization_2 (LayerNor (None, 1, 18)        36          tf.__operators__.add_1[0][0]     \n__________________________________________________________________________________________________\nmulti_head_attention_1 (MultiHe (None, 1, 18)        4818        layer_normalization_2[0][0]      \n                                                                 layer_normalization_2[0][0]      \n__________________________________________________________________________________________________\ndropout_2 (Dropout)             (None, 1, 18)        0           multi_head_attention_1[0][0]     \n__________________________________________________________________________________________________\ntf.__operators__.add_2 (TFOpLam (None, 1, 18)        0           dropout_2[0][0]                  \n                                                                 tf.__operators__.add_1[0][0]     \n__________________________________________________________________________________________________\nlayer_normalization_3 (LayerNor (None, 1, 18)        36          tf.__operators__.add_2[0][0]     \n__________________________________________________________________________________________________\nconv1d_2 (Conv1D)               (None, 1, 64)        1216        layer_normalization_3[0][0]      \n__________________________________________________________________________________________________\ndropout_3 (Dropout)             (None, 1, 64)        0           conv1d_2[0][0]                   \n__________________________________________________________________________________________________\nconv1d_3 (Conv1D)               (None, 1, 18)        1170        dropout_3[0][0]                  \n__________________________________________________________________________________________________\ntf.__operators__.add_3 (TFOpLam (None, 1, 18)        0           conv1d_3[0][0]                   \n                                                                 tf.__operators__.add_2[0][0]     \n__________________________________________________________________________________________________\nlayer_normalization_4 (LayerNor (None, 1, 18)        36          tf.__operators__.add_3[0][0]     \n__________________________________________________________________________________________________\nmulti_head_attention_2 (MultiHe (None, 1, 18)        4818        layer_normalization_4[0][0]      \n                                                                 layer_normalization_4[0][0]      \n__________________________________________________________________________________________________\ndropout_4 (Dropout)             (None, 1, 18)        0           multi_head_attention_2[0][0]     \n__________________________________________________________________________________________________\ntf.__operators__.add_4 (TFOpLam (None, 1, 18)        0           dropout_4[0][0]                  \n                                                                 tf.__operators__.add_3[0][0]     \n__________________________________________________________________________________________________\nlayer_normalization_5 (LayerNor (None, 1, 18)        36          tf.__operators__.add_4[0][0]     \n__________________________________________________________________________________________________\nconv1d_4 (Conv1D)               (None, 1, 64)        1216        layer_normalization_5[0][0]      \n__________________________________________________________________________________________________\ndropout_5 (Dropout)             (None, 1, 64)        0           conv1d_4[0][0]                   \n__________________________________________________________________________________________________\nconv1d_5 (Conv1D)               (None, 1, 18)        1170        dropout_5[0][0]                  \n__________________________________________________________________________________________________\ntf.__operators__.add_5 (TFOpLam (None, 1, 18)        0           conv1d_5[0][0]                   \n                                                                 tf.__operators__.add_4[0][0]     \n__________________________________________________________________________________________________\nlayer_normalization_6 (LayerNor (None, 1, 18)        36          tf.__operators__.add_5[0][0]     \n__________________________________________________________________________________________________\nmulti_head_attention_3 (MultiHe (None, 1, 18)        4818        layer_normalization_6[0][0]      \n                                                                 layer_normalization_6[0][0]      \n__________________________________________________________________________________________________\ndropout_6 (Dropout)             (None, 1, 18)        0           multi_head_attention_3[0][0]     \n__________________________________________________________________________________________________\ntf.__operators__.add_6 (TFOpLam (None, 1, 18)        0           dropout_6[0][0]                  \n                                                                 tf.__operators__.add_5[0][0]     \n__________________________________________________________________________________________________\nlayer_normalization_7 (LayerNor (None, 1, 18)        36          tf.__operators__.add_6[0][0]     \n__________________________________________________________________________________________________\nconv1d_6 (Conv1D)               (None, 1, 64)        1216        layer_normalization_7[0][0]      \n__________________________________________________________________________________________________\ndropout_7 (Dropout)             (None, 1, 64)        0           conv1d_6[0][0]                   \n__________________________________________________________________________________________________\nconv1d_7 (Conv1D)               (None, 1, 18)        1170        dropout_7[0][0]                  \n__________________________________________________________________________________________________\ntf.__operators__.add_7 (TFOpLam (None, 1, 18)        0           conv1d_7[0][0]                   \n                                                                 tf.__operators__.add_6[0][0]     \n__________________________________________________________________________________________________\nlayer_normalization_8 (LayerNor (None, 1, 18)        36          tf.__operators__.add_7[0][0]     \n__________________________________________________________________________________________________\nmulti_head_attention_4 (MultiHe (None, 1, 18)        4818        layer_normalization_8[0][0]      \n                                                                 layer_normalization_8[0][0]      \n__________________________________________________________________________________________________\ndropout_8 (Dropout)             (None, 1, 18)        0           multi_head_attention_4[0][0]     \n__________________________________________________________________________________________________\ntf.__operators__.add_8 (TFOpLam (None, 1, 18)        0           dropout_8[0][0]                  \n                                                                 tf.__operators__.add_7[0][0]     \n__________________________________________________________________________________________________\nlayer_normalization_9 (LayerNor (None, 1, 18)        36          tf.__operators__.add_8[0][0]     \n__________________________________________________________________________________________________\nconv1d_8 (Conv1D)               (None, 1, 64)        1216        layer_normalization_9[0][0]      \n__________________________________________________________________________________________________\ndropout_9 (Dropout)             (None, 1, 64)        0           conv1d_8[0][0]                   \n__________________________________________________________________________________________________\nconv1d_9 (Conv1D)               (None, 1, 18)        1170        dropout_9[0][0]                  \n__________________________________________________________________________________________________\ntf.__operators__.add_9 (TFOpLam (None, 1, 18)        0           conv1d_9[0][0]                   \n                                                                 tf.__operators__.add_8[0][0]     \n__________________________________________________________________________________________________\nglobal_average_pooling1d (Globa (None, 18)           0           tf.__operators__.add_9[0][0]     \n__________________________________________________________________________________________________\ndense (Dense)                   (None, 512)          9728        global_average_pooling1d[0][0]   \n__________________________________________________________________________________________________\ndropout_10 (Dropout)            (None, 512)          0           dense[0][0]                      \n__________________________________________________________________________________________________\ndense_1 (Dense)                 (None, 1)            513         dropout_10[0][0]                 \n==================================================================================================\nTotal params: 46,621\nTrainable params: 46,621\nNon-trainable params: 0\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"history=model.fit(\n    X_train,\n    Y_train,\n    validation_split=0.2,\n    epochs=50,\n    batch_size=512,\n    callbacks=callbacks,\n)","metadata":{"execution":{"iopub.status.busy":"2022-11-15T22:41:18.578020Z","iopub.execute_input":"2022-11-15T22:41:18.578783Z","iopub.status.idle":"2022-11-15T22:42:23.325546Z","shell.execute_reply.started":"2022-11-15T22:41:18.578745Z","shell.execute_reply":"2022-11-15T22:42:23.324643Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Epoch 1/50\n","output_type":"stream"},{"name":"stderr","text":"2022-11-15 22:41:18.652965: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n2022-11-15 22:41:22.673210: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n","output_type":"stream"},{"name":"stdout","text":"104/104 [==============================] - 11s 18ms/step - loss: 0.0621 - val_loss: 0.0086\nEpoch 2/50\n104/104 [==============================] - 1s 12ms/step - loss: 0.0162 - val_loss: 0.0049\nEpoch 3/50\n104/104 [==============================] - 1s 11ms/step - loss: 0.0101 - val_loss: 0.0025\nEpoch 4/50\n104/104 [==============================] - 1s 12ms/step - loss: 0.0075 - val_loss: 0.0026\nEpoch 5/50\n104/104 [==============================] - 1s 12ms/step - loss: 0.0061 - val_loss: 0.0025\nEpoch 6/50\n104/104 [==============================] - 1s 11ms/step - loss: 0.0053 - val_loss: 0.0019\nEpoch 7/50\n104/104 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0021\nEpoch 8/50\n104/104 [==============================] - 1s 14ms/step - loss: 0.0044 - val_loss: 0.0016\nEpoch 9/50\n104/104 [==============================] - 1s 11ms/step - loss: 0.0041 - val_loss: 0.0014\nEpoch 10/50\n104/104 [==============================] - 1s 11ms/step - loss: 0.0038 - val_loss: 0.0014\nEpoch 11/50\n104/104 [==============================] - 1s 12ms/step - loss: 0.0036 - val_loss: 0.0013\nEpoch 12/50\n104/104 [==============================] - 1s 12ms/step - loss: 0.0034 - val_loss: 0.0012\nEpoch 13/50\n104/104 [==============================] - 1s 12ms/step - loss: 0.0033 - val_loss: 0.0023\nEpoch 14/50\n104/104 [==============================] - 1s 12ms/step - loss: 0.0032 - val_loss: 0.0013\nEpoch 15/50\n104/104 [==============================] - 1s 11ms/step - loss: 0.0030 - val_loss: 0.0010\nEpoch 16/50\n104/104 [==============================] - 1s 11ms/step - loss: 0.0030 - val_loss: 0.0012\nEpoch 17/50\n104/104 [==============================] - 1s 14ms/step - loss: 0.0028 - val_loss: 9.2817e-04\nEpoch 18/50\n104/104 [==============================] - 1s 13ms/step - loss: 0.0026 - val_loss: 0.0015\nEpoch 19/50\n104/104 [==============================] - 1s 13ms/step - loss: 0.0026 - val_loss: 0.0012\nEpoch 20/50\n104/104 [==============================] - 1s 13ms/step - loss: 0.0026 - val_loss: 8.9673e-04\nEpoch 21/50\n104/104 [==============================] - 1s 14ms/step - loss: 0.0025 - val_loss: 8.7856e-04\nEpoch 22/50\n104/104 [==============================] - 2s 16ms/step - loss: 0.0024 - val_loss: 9.6492e-04\nEpoch 23/50\n104/104 [==============================] - 1s 13ms/step - loss: 0.0024 - val_loss: 8.8410e-04\nEpoch 24/50\n104/104 [==============================] - 1s 12ms/step - loss: 0.0024 - val_loss: 9.6160e-04\nEpoch 25/50\n104/104 [==============================] - 1s 14ms/step - loss: 0.0023 - val_loss: 0.0011\nEpoch 26/50\n104/104 [==============================] - 1s 12ms/step - loss: 0.0023 - val_loss: 9.4926e-04\nEpoch 27/50\n104/104 [==============================] - 1s 12ms/step - loss: 0.0022 - val_loss: 0.0011\nEpoch 28/50\n104/104 [==============================] - 1s 12ms/step - loss: 0.0022 - val_loss: 8.2858e-04\nEpoch 29/50\n104/104 [==============================] - 1s 11ms/step - loss: 0.0021 - val_loss: 8.9778e-04\nEpoch 30/50\n104/104 [==============================] - 1s 12ms/step - loss: 0.0021 - val_loss: 8.6819e-04\nEpoch 31/50\n104/104 [==============================] - 1s 12ms/step - loss: 0.0020 - val_loss: 9.0904e-04\nEpoch 32/50\n104/104 [==============================] - 1s 12ms/step - loss: 0.0020 - val_loss: 8.1760e-04\nEpoch 33/50\n104/104 [==============================] - 1s 12ms/step - loss: 0.0020 - val_loss: 7.6561e-04\nEpoch 34/50\n104/104 [==============================] - 1s 14ms/step - loss: 0.0020 - val_loss: 7.6988e-04\nEpoch 35/50\n104/104 [==============================] - 1s 12ms/step - loss: 0.0019 - val_loss: 8.8851e-04\nEpoch 36/50\n104/104 [==============================] - 1s 12ms/step - loss: 0.0019 - val_loss: 8.5020e-04\nEpoch 37/50\n104/104 [==============================] - 1s 11ms/step - loss: 0.0019 - val_loss: 8.1669e-04\nEpoch 38/50\n104/104 [==============================] - 1s 12ms/step - loss: 0.0018 - val_loss: 9.3515e-04\nEpoch 39/50\n104/104 [==============================] - 1s 12ms/step - loss: 0.0019 - val_loss: 0.0010\nEpoch 40/50\n104/104 [==============================] - 1s 12ms/step - loss: 0.0018 - val_loss: 8.6156e-04\nEpoch 41/50\n104/104 [==============================] - 1s 12ms/step - loss: 0.0018 - val_loss: 9.8250e-04\nEpoch 42/50\n104/104 [==============================] - 1s 12ms/step - loss: 0.0018 - val_loss: 7.9922e-04\nEpoch 43/50\n104/104 [==============================] - 1s 14ms/step - loss: 0.0017 - val_loss: 8.4695e-04\n","output_type":"stream"}]},{"cell_type":"code","source":"model.evaluate(X_train, Y_train, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2022-11-15T22:42:23.327648Z","iopub.execute_input":"2022-11-15T22:42:23.328631Z","iopub.status.idle":"2022-11-15T22:42:54.036821Z","shell.execute_reply.started":"2022-11-15T22:42:23.328593Z","shell.execute_reply":"2022-11-15T22:42:54.035669Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"2073/2073 [==============================] - 9s 4ms/step - loss: 9.0298e-04\n","output_type":"stream"},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"0.0009029849315993488"},"metadata":{}}]},{"cell_type":"code","source":"model.evaluate(X_test, y_test, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2022-11-15T22:42:54.040673Z","iopub.execute_input":"2022-11-15T22:42:54.041018Z","iopub.status.idle":"2022-11-15T22:42:56.222902Z","shell.execute_reply.started":"2022-11-15T22:42:54.040989Z","shell.execute_reply":"2022-11-15T22:42:56.221758Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"445/445 [==============================] - 2s 5ms/step - loss: 8.2325e-04\n","output_type":"stream"},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"0.0008232452673837543"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_squared_log_error, mean_absolute_percentage_error\ndef root_mean_squared_error(y_true, y_pred):    \n    return np.sqrt(mean_squared_error(y_true, y_pred))\ndef root_mean_squared_log_error(real, predicted):\n    sum=0.0\n    for x in range(len(predicted)):\n        if predicted[x]<0 or real[x]<0: # check for negative values\n            continue\n        p = np.log(predicted[x]+1)\n        r = np.log(real[x]+1)\n        sum = sum + (p - r)**2\n    return (sum/len(predicted))**0.5\ndef print_metrics():\n    print('Train   RMSE  value   : %.3f ' % root_mean_squared_error(Y_train, model.predict(X_train)))\n    print('Train   MSE   value   : %.3f ' % mean_squared_error(Y_train, model.predict(X_train)))\n    print('Train   R2    value   : %.3f ' % r2_score(Y_train,model.predict(X_train)))\n    print('Train   MAPE  value   : %.3f ' % mean_absolute_percentage_error(Y_train, model.predict(X_train)))\n    print('Train   RMLSE value   : %.3f ' % root_mean_squared_log_error(Y_train, model.predict(X_train)))\n    print('Train   MAE   value   : %.3f ' % mean_absolute_error(Y_train, model.predict(X_train)))\n    print('---------------------------------------------')\n    print('Test    RMSE  value   : %.3f ' % root_mean_squared_error(y_test, model.predict(X_test)))\n    print('Test    MSE   value   : %.3f ' % mean_squared_error(y_test, model.predict(X_test)))\n    print('Test    R2    value   : %.3f ' % r2_score(y_test, model.predict(X_test)))\n    print('Test    MAPE  value   : %.3f ' % mean_absolute_percentage_error(y_test, model.predict(X_test)))\n    print('Test    RMLSE value   : %.3f ' % root_mean_squared_log_error(y_test, model.predict(X_test)))\n    print('Test    MAE   value   : %.3f ' % mean_absolute_error(y_test, model.predict(X_test)))","metadata":{"execution":{"iopub.status.busy":"2022-11-15T22:42:56.225843Z","iopub.execute_input":"2022-11-15T22:42:56.226128Z","iopub.status.idle":"2022-11-15T22:42:56.237117Z","shell.execute_reply.started":"2022-11-15T22:42:56.226102Z","shell.execute_reply":"2022-11-15T22:42:56.236070Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"print_metrics()","metadata":{"execution":{"iopub.status.busy":"2022-11-15T22:42:56.238284Z","iopub.execute_input":"2022-11-15T22:42:56.238807Z","iopub.status.idle":"2022-11-15T22:44:05.328066Z","shell.execute_reply.started":"2022-11-15T22:42:56.238769Z","shell.execute_reply":"2022-11-15T22:44:05.326965Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Train   RMSE  value   : 0.030 \nTrain   MSE   value   : 0.001 \nTrain   R2    value   : 0.992 \nTrain   MAPE  value   : 1735798972.020 \nTrain   RMLSE value   : 0.022 \nTrain   MAE   value   : 0.016 \n---------------------------------------------\nTest    RMSE  value   : 0.029 \nTest    MSE   value   : 0.001 \nTest    R2    value   : 0.993 \nTest    MAPE  value   : 0.230 \nTest    RMLSE value   : 0.021 \nTest    MAE   value   : 0.016 \n","output_type":"stream"}]},{"cell_type":"code","source":"from matplotlib import pyplot as plt\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title(\"Plot of loss vs epoch for train and test dataset\")\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper right')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-11-15T22:44:05.329498Z","iopub.execute_input":"2022-11-15T22:44:05.329992Z","iopub.status.idle":"2022-11-15T22:44:05.555552Z","shell.execute_reply.started":"2022-11-15T22:44:05.329953Z","shell.execute_reply":"2022-11-15T22:44:05.554611Z"},"trusted":true},"execution_count":26,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]}]}